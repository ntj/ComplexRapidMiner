<?xml version="1.0" encoding="UTF-8"?>
<process version="4.0beta2">

  <operator name="Root" class="Process">
      <description text="#ylt#p#ygt# Transformations of the attribute space may ease learning in a way, that simple learning schemes may be able to learn complex functions. This is the basic idea of the kernel trick. But even without kernel based learning schemes the transformation of feature space may be necessary to reach good learning results. #ylt#/p#ygt#  #ylt#p#ygt# RapidMiner offers several different feature selection, construction, and extraction methods. This selection experiment (the well known forward selection) uses an inner cross validation for performance estimation. This building block serves as fitness evaluation for all candidate feature sets. Since the performance of a certain learning scheme is taken into account we refer to experiments of this type as #yquot#wrapper approaches#yquot#.#ylt#/p#ygt#  #ylt#p#ygt#Additionally the experiment log operator plots intermediate results. You can inspect them online in the Results tab. Please refer to the visualization sample experiments or the RapidMiner tutorial for further details.#ylt#/p#ygt#  #ylt#p#ygt# Try the following: #ylt#ul#ygt# #ylt#li#ygt#Start the experiment and change to #yquot#Result#yquot# view. There can be a plot selected. Plot the #yquot#performance#yquot# against the #yquot#generation#yquot# of the feature selection operator.#ylt#/li#ygt# #ylt#li#ygt#Select the feature selection operator in the tree view. Change the search directory from forward (forward selection) to backward (backward elimination). Restart the experiment. All features will be selected.#ylt#/li#ygt# #ylt#li#ygt#Select the feature selection operator. Right click to open the context menu and repace the operator by another feature selection scheme (for example a genetic algorithm).#ylt#/li#ygt# #ylt#li#ygt#Have a look at the list of the experiment log operator. Every time it is applied it collects the specified data. Please refer to the RapidMiner Tutorial for further explanations. After changing the feature selection operator to the genetic algorithm approach, you have to specify the correct values. #ylt#table#ygt##ylt#tr#ygt##ylt#td#ygt##ylt#icon#ygt#groups/24/visualization#ylt#/icon#ygt##ylt#/td#ygt##ylt#td#ygt##ylt#i#ygt#Use the experiment log operator to log values online.#ylt#/i#ygt##ylt#/td#ygt##ylt#/tr#ygt##ylt#/table#ygt# #ylt#/li#ygt# #ylt#/ul#ygt# #ylt#/p#ygt#"/>
      <operator name="Input" class="ExampleSource">
          <parameter key="attributes"	value="../data/polynomial.aml"/>
      </operator>
      <operator name="FS" class="FeatureSelection">
          <operator name="XValidation" class="XValidation">
              <parameter key="sampling_type"	value="shuffled sampling"/>
              <operator name="NearestNeighbors" class="NearestNeighbors">
                  <parameter key="k"	value="5"/>
              </operator>
              <operator name="ApplierChain" class="OperatorChain">
                  <operator name="Applier" class="ModelApplier">
                      <list key="application_parameters">
                      </list>
                  </operator>
                  <operator name="SimplePerformance" class="SimplePerformance">
                  </operator>
              </operator>
          </operator>
          <operator name="ExpLog" class="ProcessLog">
              <list key="log">
                <parameter key="generation"	value="operator.FS.value.generation"/>
                <parameter key="performance"	value="operator.FS.value.performance"/>
              </list>
          </operator>
      </operator>
  </operator>

</process>
