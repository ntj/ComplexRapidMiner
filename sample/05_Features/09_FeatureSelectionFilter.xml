<operator name="Root" class="Process">
    <description text="#ylt#p#ygt# Feature selection, i.e. the question for the most relevant features for classification or regression problems, is one of the main data mining tasks. A wide range of search methods was integrated into RapidMiner including evolutionary algorithms, hill climbing, and exhaustive search. For all these search methods we need a performance measurement which indicates how well a search point (a feature (sub-)set) will probably perform on the given data set. #ylt#/p#ygt# #ylt#p#ygt# We know two basic approaches to tackle this measurement problem: feature filters and wrapper approaches. The latter uses a user specified learning scheme and evaluates the desired performance with an operator like cross validation. Filter methods do not take certain learning schemes into account. They are usually faster than wrapper approaches but may not lead to the optimal feature set for a given data set and learning task. In this experiment we combine a generic search heuristic with a fast and learner-independant feature subset evaluation.#ylt#/p#ygt# #ylt#p#ygt# This experiment uses a genetic algorithm to search for the best subset of features and a Correlation based feature subset evaluation. #ylt#table#ygt# #ylt#tr#ygt##ylt#td#ygt##ylt#icon#ygt#groups/24/preprocessing#ylt#/icon#ygt##ylt#/td#ygt##ylt#td#ygt##ylt#i#ygt#A genetic algorithm can be used in order to search for an optimal feature subset.#ylt#/i#ygt##ylt#/td#ygt##ylt#/tr#ygt# #ylt#tr#ygt##ylt#td#ygt##ylt#icon#ygt#groups/24/validation#ylt#/icon#ygt##ylt#/td#ygt##ylt#td#ygt##ylt#i#ygt#The operator CFSFeatureSetEvaluator is a filter based evaluation method.#ylt#/i#ygt##ylt#/td#ygt##ylt#/tr#ygt# #ylt#/table#ygt# #ylt#/p#ygt# #ylt#p#ygt# Try the following:  #ylt#ul#ygt# #ylt#li#ygt#Start the experiment and change to #yquot#Result#yquot# view. The polynomial producing the input data set actually depends on the first three features which were all selected.#ylt#/li#ygt# #ylt#li#ygt#Replace the search method by another one, e.g. a FeatureSelection operator with a forward selection or backward elimination parameter setting.#ylt#/li#ygt# #ylt#li#ygt#Replace the evaluation method (the inner operator) by a XValidation building block including a learning scheme which can handle numerical values (e.g. KNN, mySVM,...)#ylt#/li#ygt# #ylt#/ul#ygt# #ylt#/p#ygt#"/>
    <parameter key="random_seed"	value="2000"/>
    <operator name="ExampleSource" class="ExampleSource">
        <parameter key="attributes"	value="../data/polynomial.aml"/>
    </operator>
    <operator name="NoiseGenerator" class="NoiseGenerator">
        <parameter key="label_noise"	value="0.0"/>
        <list key="noise">
        </list>
        <parameter key="random_attributes"	value="10"/>
    </operator>
    <operator name="GeneticAlgorithm" class="GeneticAlgorithm">
        <parameter key="maximum_number_of_generations"	value="15"/>
        <parameter key="population_size"	value="4"/>
        <operator name="CFSFeatureSetEvaluator" class="CFSFeatureSetEvaluator">
        </operator>
        <operator name="ProcessLog" class="ProcessLog">
            <list key="log">
              <parameter key="generation"	value="operator.GeneticAlgorithm.value.generation"/>
              <parameter key="best"	value="operator.GeneticAlgorithm.value.best"/>
              <parameter key="performance"	value="operator.GeneticAlgorithm.value.performance"/>
            </list>
        </operator>
    </operator>
</operator>

